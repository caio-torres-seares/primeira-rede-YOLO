{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEZ45bpeQ2WFA/w1fndxQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caio-torres-seares/primeira-rede-YOLO/blob/main/primeira_rede_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34NkIg_UJUui",
        "outputId": "b603fd74-2364-4bda-95de-039c83834b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando api do coco\n",
        "!pip install pycocotools\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlJ3XJdLLkur",
        "outputId": "f41f4077-12cb-441b-aa9a-34dc0d93af10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools) (2.0.2)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.202-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.202-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.202 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP8m6a0Rlmj-",
        "outputId": "5a3b8242-9e25-4e5f-beba-00eca9e265a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clona o repositório do darknet para o ambiente do Colab\n",
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pFsKIFMKy3T",
        "outputId": "5e0a4abb-6a36-4e10-b633-9ca9a84a9d01"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 15909, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 15909 (delta 2), reused 2 (delta 2), pack-reused 15903 (from 2)\u001b[K\n",
            "Receiving objects: 100% (15909/15909), 14.46 MiB | 15.46 MiB/s, done.\n",
            "Resolving deltas: 100% (10705/10705), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entra na pasta do darknet\n",
        "%cd darknet\n",
        "\n",
        "# Modifica o Makefile para habilitar GPU, CUDNN e OpenCV\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "# Compila o darknet (isso pode levar alguns minutos)\n",
        "!make"
      ],
      "metadata": {
        "id": "rIiPB7o5K4ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/annotations\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/\n",
        "!unzip data/annotations_trainval2017.zip -d data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D7GrfddMfpj",
        "outputId": "bd83d018-9dcc-4cb2-c4f5-a832d068d3b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 00:42:37--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.12.113, 16.182.34.65, 3.5.29.214, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.12.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘data/annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  16.8MB/s    in 16s     \n",
            "\n",
            "2025-09-20 00:42:54 (14.6 MB/s) - ‘data/annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  data/annotations_trainval2017.zip\n",
            "  inflating: data/annotations/instances_train2017.json  \n",
            "  inflating: data/annotations/instances_val2017.json  \n",
            "  inflating: data/annotations/captions_train2017.json  \n",
            "  inflating: data/annotations/captions_val2017.json  \n",
            "  inflating: data/annotations/person_keypoints_train2017.json  \n",
            "  inflating: data/annotations/person_keypoints_val2017.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import requests, os\n",
        "\n",
        "# caminho para as anotações baixadas\n",
        "annFile = 'data/annotations/instances_train2017.json'\n",
        "coco = COCO(annFile)\n",
        "\n",
        "categories = ['dog', 'car']\n",
        "catIds = coco.getCatIds(catNms=categories)\n",
        "imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "print(f\"Total de imagens encontradas: {len(imgIds)}\")\n",
        "print(f\"Categorias: {categories}\")\n",
        "print(f\"IDs das categorias: {catIds}\")\n",
        "\n",
        "os.makedirs('data/coco_subset/images/train', exist_ok=True)\n",
        "os.makedirs('data/coco_subset/images/val', exist_ok=True)\n",
        "os.makedirs('data/coco_subset/labels/train', exist_ok=True)\n",
        "os.makedirs('data/coco_subset/labels/val', exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfO2nrUZMWrk",
        "outputId": "85892ed1-ed0b-4ea8-90a1-becf6c715135"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=13.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Total de imagens encontradas: 481\n",
            "Categorias: ['dog', 'car']\n",
            "IDs das categorias: [3, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images(img_ids, split):\n",
        "    \"\"\"\n",
        "    Baixa imagens para um split específico (train/val)\n",
        "    \"\"\"\n",
        "    for i, imgId in enumerate(img_ids):\n",
        "        try:\n",
        "            img = coco.loadImgs(imgId)[0]\n",
        "            img_data = requests.get(img['coco_url']).content\n",
        "\n",
        "            # Salvar na pasta correta (train ou val)\n",
        "            img_path = f\"data/coco_subset/images/{split}/{img['file_name']}\"\n",
        "            with open(img_path, 'wb') as handler:\n",
        "                handler.write(img_data)\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"  {split}: {i + 1} imagens baixadas\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao baixar imagem {imgId}: {e}\")\n"
      ],
      "metadata": {
        "id": "q_wt9PS1lTbQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_split_dataset(num_images=200):  # Aumentei para 200 imagens\n",
        "    \"\"\"\n",
        "    Baixa imagens e divide em treino/validação (80/20)\n",
        "    \"\"\"\n",
        "\n",
        "    # Dividir IDs em treino e validação\n",
        "    train_ids, val_ids = train_test_split(\n",
        "        imgIds[:num_images],\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Imagens de treino: {len(train_ids)}\")\n",
        "    print(f\"Imagens de validação: {len(val_ids)}\")\n",
        "\n",
        "    # Baixar imagens de treino\n",
        "    print(\"Baixando imagens de treino...\")\n",
        "    download_images(train_ids, 'train')\n",
        "\n",
        "    # Baixar imagens de validação\n",
        "    print(\"Baixando imagens de validação...\")\n",
        "    download_images(val_ids, 'val')\n",
        "\n",
        "    return train_ids, val_ids"
      ],
      "metadata": {
        "id": "ks56KmrClC01"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids, val_ids = download_and_split_dataset(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnh4ytDJlWlK",
        "outputId": "2d276af3-988e-4117-cd53-b3c1277801bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagens de treino: 160\n",
            "Imagens de validação: 40\n",
            "Baixando imagens de treino...\n",
            "  train: 10 imagens baixadas\n",
            "  train: 20 imagens baixadas\n",
            "  train: 30 imagens baixadas\n",
            "  train: 40 imagens baixadas\n",
            "  train: 50 imagens baixadas\n",
            "  train: 60 imagens baixadas\n",
            "  train: 70 imagens baixadas\n",
            "  train: 80 imagens baixadas\n",
            "  train: 90 imagens baixadas\n",
            "  train: 100 imagens baixadas\n",
            "  train: 110 imagens baixadas\n",
            "  train: 120 imagens baixadas\n",
            "  train: 130 imagens baixadas\n",
            "  train: 140 imagens baixadas\n",
            "  train: 150 imagens baixadas\n",
            "  train: 160 imagens baixadas\n",
            "Baixando imagens de validação...\n",
            "  val: 10 imagens baixadas\n",
            "  val: 20 imagens baixadas\n",
            "  val: 30 imagens baixadas\n",
            "  val: 40 imagens baixadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_labels(img_ids, split):\n",
        "    \"\"\"\n",
        "    Cria labels YOLO para um split específico\n",
        "    \"\"\"\n",
        "    print(f\"Criando labels para {split}...\")\n",
        "\n",
        "    for i, imgId in enumerate(img_ids):\n",
        "        try:\n",
        "            img_info = coco.loadImgs(imgId)[0]\n",
        "            img_name = img_info['file_name']\n",
        "            img_width = img_info['width']\n",
        "            img_height = img_info['height']\n",
        "\n",
        "            annIds = coco.getAnnIds(imgIds=imgId, catIds=catIds, iscrowd=None)\n",
        "            anns = coco.loadAnns(annIds)\n",
        "\n",
        "            lines = []\n",
        "            for ann in anns:\n",
        "                x, y, w, h = ann['bbox']  # bbox no formato COCO\n",
        "\n",
        "                # Converter para formato YOLO (normalizado)\n",
        "                x_center = (x + w/2) / img_width\n",
        "                y_center = (y + h/2) / img_height\n",
        "                w_norm = w / img_width\n",
        "                h_norm = h / img_height\n",
        "\n",
        "                # Mapear categoria para classe (0=dog, 1=car)\n",
        "                cat_name = coco.loadCats(ann['category_id'])[0]['name']\n",
        "                class_id = categories.index(cat_name)\n",
        "\n",
        "                lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
        "\n",
        "            # Salvar arquivo .txt\n",
        "            label_path = f\"data/coco_subset/labels/{split}/{img_name.replace('.jpg', '.txt')}\"\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write(\"\\n\".join(lines))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar label {imgId}: {e}\")\n",
        "\n",
        "    print(f\"Labels {split} criados com sucesso!\")"
      ],
      "metadata": {
        "id": "uRBSE-8elZCM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar labels para ambos os splits\n",
        "create_yolo_labels(train_ids, 'train')\n",
        "create_yolo_labels(val_ids, 'val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taM438vplccd",
        "outputId": "3f1719a7-4b8d-47e7-9566-e96d23f3dce9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Criando labels para train...\n",
            "Labels train criados com sucesso!\n",
            "Criando labels para val...\n",
            "Labels val criados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_yaml():\n",
        "    \"\"\"\n",
        "    Cria arquivo de configuração do dataset\n",
        "    \"\"\"\n",
        "    dataset_config = {\n",
        "        'path': '/content/data/coco_subset',  # caminho raiz do dataset\n",
        "        'train': 'images/train',              # caminho relativo para treino\n",
        "        'val': 'images/val',                  # caminho relativo para validação\n",
        "        'nc': 2,                              # número de classes\n",
        "        'names': ['dog', 'car']               # nomes das classes\n",
        "    }\n",
        "\n",
        "    yaml_path = 'data/coco_subset/dataset.yaml'\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(dataset_config, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"Arquivo dataset.yaml criado: {yaml_path}\")\n",
        "    return yaml_path"
      ],
      "metadata": {
        "id": "Hk4nbSqimGZk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_path = create_dataset_yaml()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQT1HpM3mHQe",
        "outputId": "4128808b-b943-4008-cc53-74c46e232272"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo dataset.yaml criado: data/coco_subset/dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolo_model():\n",
        "    \"\"\"\n",
        "    Treina modelo YOLO com seus dados\n",
        "    \"\"\"\n",
        "    # Carregar modelo pré-treinado\n",
        "    model = YOLO('yolov8n.pt')  # YOLOv8 nano (rápido para teste)\n",
        "\n",
        "    print(\"Iniciando treinamento YOLO...\")\n",
        "    print(\"Configurações:\")\n",
        "    print(f\"- Modelo: YOLOv8n\")\n",
        "    print(f\"- Classes: {categories}\")\n",
        "    print(f\"- Épocas: 100\")\n",
        "    print(f\"- Batch size: 16\")\n",
        "    print(f\"- Imagem: 640x640\")\n",
        "\n",
        "    # Treinar modelo\n",
        "    results = model.train(\n",
        "        data=yaml_path,           # seu dataset.yaml\n",
        "        epochs=100,               # número de épocas\n",
        "        imgsz=640,                # tamanho da imagem\n",
        "        batch=16,                 # batch size\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        project='yolo_results',   # pasta dos resultados\n",
        "        name='dog_car_detector',  # nome do experimento\n",
        "        save=True,                # salvar checkpoints\n",
        "        plots=True,               # gerar gráficos\n",
        "        patience=10,              # early stopping\n",
        "        save_period=10,           # salvar a cada 10 épocas\n",
        "        verbose=True              # logs detalhados\n",
        "    )\n",
        "\n",
        "    print(\"Treinamento concluído!\")\n",
        "    return model, results"
      ],
      "metadata": {
        "id": "iho27U7KmnMj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executar treinamento\n",
        "trained_model, training_results = train_yolo_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzDvjn1jmoIh",
        "outputId": "453bc7d4-4ee8-4368-dbfd-1236af0845ed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando treinamento YOLO...\n",
            "Configurações:\n",
            "- Modelo: YOLOv8n\n",
            "- Classes: ['dog', 'car']\n",
            "- Épocas: 100\n",
            "- Batch size: 16\n",
            "- Imagem: 640x640\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/coco_subset/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=dog_car_detector2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/darknet/yolo_results/dog_car_detector2, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 97.8MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 240.8MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1616.6±401.1 MB/s, size: 122.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/darknet/data/coco_subset/labels/train... 160 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 160/160 2.2Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/darknet/data/coco_subset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 447.0±138.4 MB/s, size: 159.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/darknet/data/coco_subset/labels/val... 40 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 40/40 1.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/darknet/data/coco_subset/labels/val.cache\n",
            "Plotting labels to /content/darknet/yolo_results/dog_car_detector2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/darknet/yolo_results/dog_car_detector2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      2.09G      1.106      3.073      1.192        125        640: 100% ━━━━━━━━━━━━ 10/10 2.4it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s\n",
            "                   all         40        167    0.00781      0.605      0.301      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      2.58G      1.195      2.178      1.224        114        640: 100% ━━━━━━━━━━━━ 10/10 5.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.9it/s 1.0s\n",
            "                   all         40        167      0.819      0.153      0.355      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100       2.6G      1.214      1.846      1.237        111        640: 100% ━━━━━━━━━━━━ 10/10 3.5it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         40        167      0.654      0.184      0.291      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      2.62G      1.214      1.815      1.267        138        640: 100% ━━━━━━━━━━━━ 10/10 5.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.2it/s 0.6s\n",
            "                   all         40        167      0.601      0.143       0.21      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      2.63G      1.261      1.722      1.286        113        640: 100% ━━━━━━━━━━━━ 10/10 2.4it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.5it/s 1.3s\n",
            "                   all         40        167      0.394      0.125      0.144     0.0834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      2.65G      1.277      1.734      1.261        124        640: 100% ━━━━━━━━━━━━ 10/10 3.6it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         40        167      0.241     0.0694     0.0661     0.0351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      2.67G      1.304      1.658      1.308        102        640: 100% ━━━━━━━━━━━━ 10/10 5.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.3it/s 0.6s\n",
            "                   all         40        167      0.111     0.0439     0.0711     0.0299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      2.69G      1.259      1.671      1.299        149        640: 100% ━━━━━━━━━━━━ 10/10 4.1it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.8it/s 0.7s\n",
            "                   all         40        167      0.563     0.0658     0.0528     0.0249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100       2.7G      1.274      1.693        1.3        127        640: 100% ━━━━━━━━━━━━ 10/10 3.9it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.6it/s 0.8s\n",
            "                   all         40        167      0.192     0.0597     0.0559     0.0181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      2.72G      1.269      1.671      1.295        106        640: 100% ━━━━━━━━━━━━ 10/10 3.7it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.2it/s 0.6s\n",
            "                   all         40        167     0.0825      0.105     0.0594     0.0251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      2.73G      1.276      1.625      1.271         97        640: 100% ━━━━━━━━━━━━ 10/10 4.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 3.7it/s 0.5s\n",
            "                   all         40        167      0.156      0.123     0.0778     0.0337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      2.75G      1.264      1.621      1.271        152        640: 100% ━━━━━━━━━━━━ 10/10 4.7it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.2it/s 0.5s\n",
            "                   all         40        167     0.0612      0.202      0.046     0.0224\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "12 epochs completed in 0.013 hours.\n",
            "Optimizer stripped from /content/darknet/yolo_results/dog_car_detector2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/darknet/yolo_results/dog_car_detector2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/darknet/yolo_results/dog_car_detector2/weights/best.pt...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 4.3it/s 0.5s\n",
            "                   all         40        167      0.819      0.153      0.355      0.233\n",
            "                   dog         40         53          1      0.281      0.533      0.368\n",
            "                   car         40        114      0.638     0.0263      0.176     0.0978\n",
            "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/darknet/yolo_results/dog_car_detector2\u001b[0m\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model):\n",
        "    \"\"\"\n",
        "    Valida o modelo treinado - VERSÃO CORRIGIDA\n",
        "    \"\"\"\n",
        "    print(\"Validando modelo...\")\n",
        "\n",
        "    # Executar validação\n",
        "    val_results = model.val()\n",
        "\n",
        "    print(\"Métricas de Validação:\")\n",
        "    print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
        "    print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
        "\n",
        "    try:\n",
        "        if hasattr(val_results.box, 'mp') and hasattr(val_results.box, 'mr'):\n",
        "            mp = val_results.box.mp\n",
        "            mr = val_results.box.mr\n",
        "\n",
        "            print(f\"\\nTipo de mp: {type(mp)}\")\n",
        "            print(f\"Valor de mp: {mp}\")\n",
        "            print(f\"Tipo de mr: {type(mr)}\")\n",
        "            print(f\"Valor de mr: {mr}\")\n",
        "\n",
        "            if hasattr(mp, '__len__') and len(mp) > 1:\n",
        "                print(\"\\nMétricas por classe:\")\n",
        "                for i, class_name in enumerate(categories):\n",
        "                    if i < len(mp):\n",
        "                        precision = mp[i]\n",
        "                        recall = mr[i]\n",
        "                        print(f\"{class_name}: Precision={precision:.4f}, Recall={recall:.4f}\")\n",
        "            else:\n",
        "                print(f\"\\nPrecision geral: {mp:.4f}\")\n",
        "                print(f\"Recall geral: {mr:.4f}\")\n",
        "\n",
        "        if hasattr(val_results.box, 'maps'):\n",
        "            maps = val_results.box.maps\n",
        "            if hasattr(maps, '__len__') and len(maps) > 1:\n",
        "                print(\"\\nmAP50 por classe:\")\n",
        "                for i, class_name in enumerate(categories):\n",
        "                    if i < len(maps):\n",
        "                        print(f\"{class_name}: {maps[i]:.4f}\")\n",
        "\n",
        "        print(f\"\\nInformações adicionais:\")\n",
        "        if hasattr(val_results.box, 'nc'):\n",
        "            print(f\"Número de classes: {val_results.box.nc}\")\n",
        "        if hasattr(val_results.box, 'nt'):\n",
        "            print(f\"Total de targets: {val_results.box.nt}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao acessar métricas detalhadas: {e}\")\n",
        "        print(\"Mostrando apenas métricas principais.\")\n",
        "\n",
        "    return val_results\n"
      ],
      "metadata": {
        "id": "tADLAoNgmssx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar modelo\n",
        "validation_results = validate_model(trained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjfVHHOKpL0O",
        "outputId": "09c70095-9088-47f2-c7d8-ee0acbe1cfbc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validando modelo...\n",
            "Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1539.6±275.6 MB/s, size: 161.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/darknet/data/coco_subset/labels/val.cache... 40 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 40/40 68.5Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s\n",
            "                   all         40        167      0.817      0.144      0.363      0.237\n",
            "                   dog         40         53          1      0.262      0.552       0.38\n",
            "                   car         40        114      0.633     0.0263      0.174      0.095\n",
            "Speed: 6.3ms preprocess, 9.8ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/darknet/yolo_results/dog_car_detector24\u001b[0m\n",
            "Métricas de Validação:\n",
            "mAP50: 0.3634\n",
            "mAP50-95: 0.2373\n",
            "\n",
            "Tipo de mp: <class 'numpy.float64'>\n",
            "Valor de mp: 0.8166612155435061\n",
            "Tipo de mr: <class 'numpy.float64'>\n",
            "Valor de mr: 0.14417613378202893\n",
            "\n",
            "Precision geral: 0.8167\n",
            "Recall geral: 0.1442\n",
            "\n",
            "mAP50 por classe:\n",
            "dog: 0.3796\n",
            "car: 0.0950\n",
            "\n",
            "Informações adicionais:\n",
            "Número de classes: 2\n"
          ]
        }
      ]
    }
  ]
}